# Dog Breed Identifier - Backend Project Report

## 1. Executive Summary
The **Dog Breed Identifier Backend** is a high-performance, cloud-native API designed to serve the machine learning inference needs of the application. It is architected to run within a **Google Colab** environment, leveraging the platform's free T4 GPU resources to execute computationally intensive deep learning models. The backend exposes a RESTful API via **FastAPI**, tunneled to the public internet using **Ngrok**, and maintains persistent data logs using **Supabase**.

## 2. Technology Stack

The backend infrastructure is built on a foundation of high-performance, industry-standard tools designed for scalable AI inference.

### Core Frameworks & Runtime
*   **Language**: **Python 3.10+** - Selected for its dominance in the AI/ML ecosystem and rich library support.
*   **Web Framework**: **[FastAPI](https://fastapi.tiangolo.com/)**
    *   *Role*: Serves as the main API gateway.
    *   *Why*: Built on Starlette for high performance, offers native async support (crucial for I/O bound tasks like network requests), and provides automatic OpenAPI (Swagger) documentation.
*   **ASGI Server**: **[Uvicorn](https://www.uvicorn.org/)**
    *   *Role*: The lightning-fast ASGI server that runs the FastAPI application.
    *   *Why*: Essential for handling asynchronous requests efficiently in a production-like environment.
*   **Runtime Environment**: **[Google Colab](https://colab.research.google.com/)**
    *   *Role*: Provides the execution environment.
    *   *Why*: Grants free access to powerful NVIDIA T4 GPUs, which are necessary for running the ConvNeXt model inference with low latency.

### Networking & Infrastructure
*   **Tunneling**: **[Ngrok](https://ngrok.com/)** (via `pyngrok`)
    *   *Role*: Exposes the localhost server running inside the isolated Colab environment to the public internet.
    *   *Why*: Colab instances do not have static public IPs; Ngrok provides a secure, temporary public URL for the frontend to consume.
*   **Database**: **[Supabase](https://supabase.com/)** (PostgreSQL)
    *   *Role*: A fully managed, open-source Firebase alternative used for persistent logging.
    *   *Why*: Offers a robust PostgreSQL database with a RESTful API layer, which is critical for connectivity from Colab.
*   **Client Library**: **`supabase-py`**
    *   *Role*: Python client for Supabase.
    *   *Why*: Enables database interaction via HTTPS (port 443), bypassing Google Colab's strict firewall that blocks standard PostgreSQL ports (5432).

### Data Processing & Utilities
*   **Image Processing**: **[Pillow (PIL)](https://python-pillow.org/)**
    *   *Role*: Handles image opening, validation, resizing, and format conversion before model inference.
*   **Numerical Computing**: **[NumPy](https://numpy.org/)**
    *   *Role*: The fundamental package for scientific computing, used for efficient array manipulations and tensor operations required by TensorFlow.
*   **Environment Management**: **`python-dotenv`**
    *   *Role*: Loads configuration and sensitive credentials (API keys) from `.env` files, ensuring security best practices.
*   **Request Handling**: **`python-multipart`**
    *   *Role*: Parses multipart form data, enabling the API to handle file uploads and complex form submissions.

## 3. System Architecture

### High-Level Data Flow
1.  **Request**: The Next.js frontend sends a POST request to the Ngrok public URL (e.g., `https://xyz.ngrok-free.app/predict`) containing the image URL.
2.  **Tunneling**: Ngrok forwards this request to the local Uvicorn server running inside the Google Colab instance.
3.  **Routing**: FastAPI receives the request and routes it to the `/predict` endpoint.
4.  **Processing**:
    *   The image is downloaded from the provided URL.
    *   A SHA-256 hash is computed to check for cached results in Supabase.
    *   **Stage 1 (Detection)**: A YOLOv8 Nano model checks if a dog is present.
    *   **Stage 2 (Classification)**: If a dog is detected, a ConvNeXt Base model predicts the breed.
5.  **Persistence**: The result (or lack thereof) is logged to the Supabase `image_logs` table.
6.  **Response**: The predicted breed index is returned to the frontend as a JSON response.

## 4. Database Design & Implementation

### Overview
The backend utilizes **Supabase**, a modern open-source Firebase alternative built on top of **PostgreSQL**. This choice provides the robustness of a relational database with the ease of use of a backend-as-a-service (BaaS) platform.

### Schema Design
The database consists of a primary table `image_logs` designed to track every inference request. This serves two purposes: **Analytics** (tracking usage and model performance) and **Caching** (avoiding re-processing the same image).

#### Table: `image_logs`

| Column Name | Data Type | Constraints | Description |
| :--- | :--- | :--- | :--- |
| `id` | `bigint` | `PRIMARY KEY`, `GENERATED BY DEFAULT AS IDENTITY` | Unique identifier for each log entry. |
| `image_hash` | `text` | `UNIQUE`, `NOT NULL` | A SHA-256 hash of the image file content. This is the **critical** field used for caching. |
| `image_url` | `text` | `NOT NULL` | The source URL of the image provided by the frontend. |
| `is_dog` | `boolean` | `DEFAULT FALSE` | The result of the YOLOv8 detection step. `True` if a dog was detected, `False` otherwise. |
| `breed_label` | `integer` | `NULLABLE` | The predicted class index (0-119) from the ConvNeXt model. Null if `is_dog` is False. |
| `created_at` | `timestamptz` | `DEFAULT now()` | Timestamp of when the request was processed. |

### Connection Strategy: The "Colab Problem"
A significant engineering challenge was connecting to the database from Google Colab.
*   **The Problem**: Google Colab environments sit behind a strict firewall that blocks outbound traffic on non-standard ports, including the default PostgreSQL port **5432**. This prevents standard database drivers like `psycopg2` or `SQLAlchemy` from establishing a connection.
*   **The Solution**: We utilized the **Supabase Python Client** (`supabase-py`). Instead of a direct TCP connection to the database port, this client interacts with Supabase via its **REST API** over standard **HTTPS (Port 443)**. Since Colab allows HTTPS traffic, this provides a reliable and secure channel for database operations.

### Data Access Patterns

#### 1. The "Cache Hit" Query
Before processing any image, the backend queries the database to see if this exact image has been seen before.
```python
response = supabase.table("image_logs").select("*").eq("image_hash", image_hash).execute()
```
*   **Logic**: If a record is found, the system immediately returns the stored `breed_label` (or raises a "No Dog" exception if `is_dog` is False). This bypasses the expensive GPU inference steps, significantly reducing latency for repeated requests.

#### 2. The "Log Result" Insert
After a new image is processed, the result is inserted into the database.
```python
new_log = {
    "image_hash": image_hash,
    "image_url": image_url,
    "is_dog": True,  # or False
    "breed_label": label_number
}
supabase.table("image_logs").insert(new_log).execute()
```
*   **Logic**: This persists the result, ensuring that future requests for this image will be served from the cache.

## 5. API Documentation

### Base URL
The Base URL is dynamic and generated by Ngrok upon startup (e.g., `https://<random-id>.ngrok-free.app`).

### Endpoints

#### `GET /`
*   **Description**: Health check endpoint to verify the API is running.
*   **Response**: `{"message": "Welcome to the Dog Breed Identification API!"}`

#### `POST /predict`
*   **Description**: The main inference endpoint.
*   **Request Body**:
    ```json
    {
      "image_url": "https://example.com/dog.jpg"
    }
    ```
*   **Success Response (200 OK)**:
    ```json
    {
      "label_number": 42
    }
    ```
*   **Error Responses**:
    *   `400 Bad Request`: "No dog detected in the image."
    *   `500 Internal Server Error`: General processing failure.

## 6. Implementation Details

### Machine Learning Pipeline Integration
The backend orchestrates a sophisticated pipeline:
1.  **Download**: Fetches image bytes from the URL.
2.  **Hashing**: Computes SHA-256 hash.
3.  **DB Check**: Queries Supabase for the hash.
4.  **YOLO Inference**: Runs `ultralytics` YOLOv8 model to detect `dog` class.
5.  **ConvNeXt Inference**: Runs the fine-tuned Keras model for classification.
6.  **DB Write**: Logs the final outcome.

### Security Configuration
*   **CORS (Cross-Origin Resource Sharing)**: Configured to allow requests from `http://localhost:3000` and `http://localhost:5173` to support local frontend development.
*   **Environment Variables**: Sensitive credentials (`SUPABASE_URL`, `SUPABASE_KEY`, `ngrok_auth_token`) are injected via environment variables and never hardcoded in the source files.

## 7. Future Enhancements
*   **Model Quantization**: Convert models to TensorFlow Lite or ONNX for faster CPU inference, reducing reliance on GPUs.
*   **Asynchronous Processing**: Implement a task queue (like Celery) for handling high loads without blocking the API.
*   **Automated Retraining**: A pipeline to automatically retrain the model using the logged images in Supabase.
